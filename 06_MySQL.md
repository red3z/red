---
title: MySQL专题
tags:
  - null
categories:
  - Java基础
mathjax: true
description: MySQL笔记
abbrlink: ebbea089
date: 2024-11-06 11:39:21
---

varchar(5)和varchar(500)性能有区别吗

MySQL进行写操作会默认加锁吗?

索引合并

Intersection

Union

Sort-Union



# 一条SQL的执行过程

MySQL架构分为两层: Server层, 存储引擎



连接器: 基于TCP三次握手建立连接, 校验密码与权限, 半双工连接接收到SQL

解析器: 解析SQL, 包括词法分析, 语法分析生成语法树

预处理器: 判断表名, 字段名是否存在; 将*扩展为表上所由列;

优化器: 确定SQL的执行计划. 1.选择最佳索引; 2.简化重组查询条件, 以符合最左匹配原则;

执行器: B+树搜索, 从存储引擎读取记录.

引擎层: 现在内存的BufferPool中看数据是否存在; 如果没有会去磁盘中找, 查询到会放在BufferPool中; 最后记录日志, 包括BinLog, UndoLog, RedoLog.



==索引下推==: 

> select * from t_user where age > 20 and reward = 1000;
>
> index: age+reward

age能用到索引, reward用不到.

如果没有索引下推: 

1. Server存储引擎的接口; 
   2. 存储引擎定位到age>20的第一条记录
   2. 根据id回表
   2. 将完整记录返回给Server; 
2. <u>Server判断reward</u>, 如果=1000则返回, 如果!=则跳过; 循环

如果有索引下推:

1. Server循环调用存储引擎的接口:
   1. 存储引擎定位到age>20的第一条记录
   2. <u>存储引擎判断reward</u>, 如果=1000则回表, 如果!=则跳过;
2. Server判断其他查询条件, 如果成立返回, 不成立跳过; 循环



> UPDATE t_user SET name = 'red' WHERE id = 1;

1. 执行器调用存储引擎接口读数据:
   1. 存储引擎 判断buffer pool中是否存在 id=1 所属页的数据, 如果存在直接返回; 如果不在, 将数据页从磁盘中读入到buffer pool, 返回.
2. 执行器 判断存储引擎返回的数据 是否一致. 如果不一致, 调用存储引擎接口写数据:
   1. 开启事务
   2. 将旧值记录在undo_log, undo_log写入buffer pool的undo页面. 在修改该undo页面后, 记录redo_log
   3. 更新内存, 将其标记为脏页, 将记录写入redo_log. (后台线程选择合适的时机将脏页写入磁盘)
   4. bin_log信息先保存在binLog cache
   5. 提交事务, 将bin_log写入磁盘.





# MySQL日志

写操作会涉及到日志, 

| MySQL日志  |                                                              |
| ---------- | ------------------------------------------------------------ |
| undo log   | 存储引擎生成undo log, 记录事务修改前的值, 用于事务回滚实现事务原子性 |
| redo log   | 存储引擎生成redo log, 记录事务修改后的状态, 故障恢复, 实现事务持久性. WAL(Write Ahead Logging)先==顺序写==日志, 再随机写磁盘. 边写边擦除日志, 只记录未被写入磁盘的数据. |
| binlog     | 归档日志, Server生成binlog,  所有存储引擎都可以用, 保存全量日志, 用于数据备份和主从复制. |
| 慢查询日志 |                                                              |



## 二阶段提交

redo_log和bin_log可能一个成功一个失败, 导致主从数据不一致, 用二阶段提交解决.



通过一个标识来确定持久化到了哪一步.

先持久化redoLog. 如果刚持久化完redoLog出了问题, 就回滚.

再持久化binLog. 如果持久化完binLog出了问题, 就提交事务.





# BufferPool

索引页, 数据页, undo页

插入缓存页, 自适应哈希索引, 锁信息



LRU产生的预读失效问题: 预读进来的页不确定会不会被访问, 却会把更大可能被访问的页给挤掉.

解决方案: 将LRU分成两个区, old和young. 预读的放在old, 被访问到的放在young. 挤的时候把old的给挤掉.



Buffer 污染的问题: 全表扫描, Buffer Pool中的数据不断被替换. 

解决方案: 只有同时满足被访问和在old呆够1s, 才会到young.



# 一行记录的存储结构

一张表存在 表名.ibd.

**存储引擎是啥东西?**

存储引擎是基于表的, 一个数据库的不同表可以用不同的存储引擎. 决定了数据在磁盘上的存储形式.

InnoDB引擎, 支持ACID事务, 不支持外键, 支持表锁和行锁, 索引和数据一起存储, 索引的数据结构都是B+.



页: InnoDB一次IO读取一页16KB, 表的行信息存在页中.

区: 64个页为一个区1MB, 使得链表相邻的页物理位置也相邻.



COMPACT行格式: 

| 变长字段长度列表 | NULL列表                 | 头信息 | row_id | trx_id | roll_ptr     | 列1  | 列2  |
| ---------------- | ------------------------ | ------ | ------ | ------ | ------------ | ---- | ---- |
| 变长字段占用的B  | 可NULL字段是否为NULL, 1B |        | 6Byte  | 6B     | MVCC上个版本 |      |      |

一行记录限制最大为65535B.

如果用TEXT, BLOB这些大数据, 可能一页存不下一行数据, 行溢出, 放到溢出页, 用20B指针指向溢出页.



# 索引

一张表, 每一行1KB大小, 有5000万数据, 主键long, 求B+树有几层:

叶子结点: 5000kB / 16k 

非叶子结点: 一页: 16kB / 8B = 2k个主键, 5000万 / 2k = 25000个非叶子结点

1

2000

2000 * 2000



| 索引     | 索引可以让读写更快. 因为写操作是先将数据读出来修改后再写回磁盘, 因此写也会更快. |
| -------- | ------------------------------------------------------------ |
| 哈希     | 实现不了范围查找between ... and ..., 排序order by ..., 组合索引; 哈希冲突会退化为链表; 浪费内存 |
| AVL树    | 树分支只有两个, 树太高, IO次数多, 效率低.                    |
| B树      | B树的叶子结点也存放数据, 一个内存页存放的索引少一些, 会导致IO次数多. |
| B+的优点 | 数据不存在非叶子结点, 可以在一个内存页中读更多的键, 可更快地缩小查找范围; 矮, 千万级数据量3-4层; 叶子与叶子用了双向链表, 方便范围查找; |



数据量比较大的时候, 是不能一次性把数据都读取到内存的, 所以要分块读取, ==InnoDB存储引擎每次读16KB的数据==

> 为什么InnoDB存储引擎每次读取16KB的数据?
>
> 操作系统页大小为4kb，为了让操作系统取出来的页对应我们mysql中的页，我们可以把mysql页大小设置为操作系统页的整数倍. 



MySQL数据和索引都是存在磁盘的, 磁盘在与内存交互的时候要进行IO操作, IO操作是比较慢的, 所以设计索引的核心原则就是要尽量的减少IO次数



> **回表: **从二级索引的叶子结点获取聚簇索引的id, 再根据id再去获取要查询的数据;
>
> **索引覆盖:**  不需要回表(InnoDB二级索引的叶子存储的是主键和索引列)
>
> **最左匹配: ** 
>
> ​	最左匹配的原理: A+B的联合索引, A有序, B是基于A有序. 从左向右一个一个匹配, 如果不匹配则索引中断.
>
> ​	如果where只包A, 只能把 匹配A 的数据主键ID都找到, 通过回表查询, 比全表扫描强. 
>
> ​	范围查询是无序的, 所以匹配到范围查询(between, 函数, like且第一个是通配符)就停止了

**表中没有主键的情况下, InnoDB会怎么做?**

InnoDB数据和索引放在一起(同一个文件), 而且是必须绑定

- 若没有主键, 用第一个唯一索引作为主键索引
- 既没有主键, 也没有唯一键, 用rowID作为主键索引

| 索引的分类         |                                                         |                             |
| ------------------ | ------------------------------------------------------- | --------------------------- |
| 聚簇索引, 二级索引 | 聚簇索引的叶子是整行数据, 二级索引的叶子是聚簇索引的值. | 回表 索引覆盖(就是无需回表) |
| 复合索引           |                                                         | 违背最左匹配原则会索引失效  |

为什么二级索引不存全量数据? 当有了主键索引, 再为另一个字段建了索引, 如果叶子存所有字段数据, 则数据冗余了一份. 所以二级索引的叶子结点只存主键.



| 创建索引的原则                 |                                                              |
| ------------------------------ | ------------------------------------------------------------ |
| 主键使用自增ID还是UUID         | 自增, 可以减少页分裂操作.                                    |
| 用更短数据的索引列             | 一次IO可以读到更多的索引.                                    |
| 用数据离散性更高的列           | 离散度低的数据字段不适合做索引, 比如性别. 建议直接分表存储(建个男表, 建个女表) |
| 只为搜索, 排序, 分组的列建索引 |                                                              |
| 为外键的数据列建立索引         | 当对父表(被引用的表)进行写操作时, 数据库需检查子表是否存在关联记录, 如果没有索引, 则只能全表扫描. |
| 尽量扩展索引, 少新建索引       |                                                              |
| 建多列索引的原则               | 离散型更高的在前面, 频率高的在前面, 也有可能需要相同列不同顺序的索引 |
| 三星索引原则                   | 1.不需要回表; 2.索引将相关记录放到一起不分散; 3.索引中的数据顺序和查找到的数据顺序一致. 满足一个获得1星 |

对于很长的列, 可以建前缀索引, 只对前几个字符建索引. 缺点是不能order by, 不能group by, 不能索引覆盖





索引下推

(name, age是组合索引)`select * from table where name=red and age=10;`

没有索引下推: 根据name在存储引擎拿到全量数据, 将数据读取到server层, 按照age做数据过滤

有索引下推: 根据name, age两个列在存储引擎筛选数据

从server层做的数据过滤层下推到存储引擎层



| 索引失效                           |                                                              |
| ---------------------------------- | ------------------------------------------------------------ |
| 左模糊匹配                         | select * from t_user where name like '%林';                  |
| 对索引使用了函数, MySQL8有函数索引 | select * from t_user where length(name)=6;                   |
| 对索引进行了表达式计算             | select * from t_user where id + 1 = 10;                      |
| 隐式类型转换, 整型和字符串         | select * from t_user where phone = 1300000001;               |
| 不符合最左匹配原则                 |                                                              |
| OR                                 | 在OR前的条件是索引列, 而在OR后的条件不是索引列，那么索引会失效 |



# 事务

| 事务四大特性ACID  |                                                              | 实现方式                                                     |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Atomicity原子性   | 要么全部成功, 要么全部失败                                   | ==undo_log==实现, 如果出现问题, 就恢复到执行前的状态, 执行前的状态用UndoLog记录 |
| Consistency一致性 | 执行事务之前和之后状态的一致, 例如A,B互相转账, 转来转去AB钱的总和不变 |                                                              |
| Isolation隔离性   | 并发场景下, 多个事务互相隔离. 例如A提交前, B看不到修改.      | ==MVCC实现==                                                 |
| Durability持久性  | 事务的提交永久改变数据库                                     | ==redolog实现==, MySQL写数据先往Buffer中写, (期间可能MySQL宕机)再同步到磁盘上. RedoLog记录写操作. |

RedoLog比Buffer快, 因为Buffer数据持久化每次写的位置随机, RedoLog是文件尾部append; Buffer一次写入16KB页, RedoLog只写需要的部分, 无效IO减少.



| 事务隔离级别                                                 |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 读未提交, 什么都不干                                         |                                                              |
| 读已提交, 只能读到已经提交的数据. 解决脏读问题, MVCC实现     | 脏读: 事务A读取事务B修改了的数据, ‌事务B回滚, ‌A就读取到脏数据. 不满足事务隔离性. |
| 可重复读(默认), 解决不可重复读问题, MVCC实现                 | 不可重复读: 事务A第一次读后, 事务B==修改==提交, 事务A第二次读, 数据不一样. ==某一条或几条数据== |
| 串行化, 行锁+间隙锁实现, 如果记录存在加行锁, 不存在加间隙锁锁附近范围. | 幻读: 事务A读取一条空数据结果为空, ‌事务B==插入==该数据, 事务A对该数据修改, 因为修改时创建了ReadView, 事务A再次读会读到, 多次读数据不一致. ==表级别==的问题 |

事务的保存点

事务的隐式提交, 一个事务里面执行DDL语句(创建表, 修改表, 删除表), 执行开启新事务, 开启锁会隐式提交, 把前面的全部提交.



**索引失效的情况**

| 索引失效     | 索引就是保证有序, 走索引的前提是查询条件是有序的 |
| ------------ | ------------------------------------------------ |
| 最左匹配原则 | 联合索引不查第一个条件.                          |
| >            | where a>1 and b=1, 只走a的索引                   |
| like '%a'    |                                                  |
| or           |                                                  |
| in           |                                                  |



**SQL注入是怎么解决的?**

占位符替换的时候包上单引号



# MVCC

ReadView + undo_log

在读的时候生效.

Muiti-Version Concurrency Control, 无锁实现事务的隔离性, 解决脏读, 不可重复读问题.

MVCC主要<u>处理读请求</u>, 指的是快照读, 乐观的. (与之相反的是当前读, 需要加锁)

| 表的隐藏列 |                                             |
| ---------- | ------------------------------------------- |
| 变长字段   |                                             |
| NULL       |                                             |
| 头         |                                             |
| row_id     |                                             |
| trx_id     | 这行数据所属的事务Id                        |
| roll_ptr   | 指向这行数据的上个版本数据的指针, 用于回滚. |



| ReadView     | 执行SELECT时会用ReadView来定位到底查询哪个版本的数据         |
| ------------ | ------------------------------------------------------------ |
| 包含什么东西 | m_ids当前活跃(未提交)的所有事务Id, 最小和最大事务Id, creator_trx_id. |
| 怎么定位版本 | 从新到旧依次查版本链, 查到的第一个事务id不在m_ids中的版本, 也就是已提交的版本, 从而实现读已提交. 因为只读已提交的版本, 所以会导致不可重复读. |
| 什么时候创建 | 读已提交==每次==读都会创建一个ReadView所以导致不可重复读问题; 可重复读多次读一条数据只在==第一次==创建ReadView. |

因为如果事务A第一次读之后, 事务B提交了, 事务A再次读, 根据新建的ReadView就会去读事务B提交了的数据, 解决方式是只在第一次读时创建ReadView.



| UndoLog | Undolog记录一条数据的所有修改版本, 也就是记录历史记录, 实现回滚和MVCC |
| ------- | ------------------------------------------------------------ |



# MySQL锁

## 表级别锁

| 表级别锁          |                                                              |
| ----------------- | ------------------------------------------------------------ |
| 表锁              | 共享锁(读锁), 排他锁(写锁)                                   |
| 意向锁            | 为了快速判断是否有行锁. 加读锁之前, 需要加意向读锁; 加写锁之前, 加意向独占锁. |
| 元数据锁(DML的锁) | 锁表结构, CRUD操作加DML读锁, 更改表结构加DML写锁.            |
| AUTO-INC锁        | 给字段赋值自增值就释放掉了, 不需要等插入语句执行完, 更不需要等事务执行完. |



## 行级别锁

| 行级别锁                                                     |                                         |
| ------------------------------------------------------------ | --------------------------------------- |
| 记录锁Record Lock, 锁一条记录                                |                                         |
| 间隙锁Gap Lock, 锁一个范围, 不包括记录本身                   | 目的是解决幻读问题, 间隙锁之间是兼容的. |
| 临键锁Next-Key Lock = Gap Lock + Next-Key Lock, 锁一个范围, 包括记录本身 |                                         |
| 插入意向锁                                                   |                                         |



美团面试题: 字段Number上有个普通索引, delete from 表 where number = 10, 会加哪些锁?

意向排他锁, 临键锁, 间隙锁



## MySQL死锁问题

如何避免死锁?

- 设置事务等待锁的超时时间
- 开启主动死锁检测, 检测到死锁, 会主动回滚某个事务.



# MySQL调优

优化要在几个层面考虑, 成本最低并且效果最好的是软件层优化, 也就是MySQL自身的优化.



| MySQL优化                                                    |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 建立合适的索引, MySQL读一次磁盘16K, 千万数据B+树3次IO. 建立索引的原则是合适, 索引太多反而性能会越慢. | 加索引的原则: 经常需要排序分组的字段; 区分高的字段; 有些数据太长, 可以建前缀索引, 因为字段长的话索引占用空间大, 但是要保证前缀可以区分不同的数据, 比如UUID这种前几个字符就可以识别一条记录的字段. |
| 避免全表扫描的SQL                                            |                                                              |
|                                                              |                                                              |
|                                                              |                                                              |

关联字段类型不一致导致全表扫描:

一张模板表, 一张审批表, 模板不一定有审批, 所以模板表左关联审批表去分页查询, 两边差不多有几千数据查询10条数据却要700毫秒, 当时我就仔细分析了一下两边的数据类型, 发现模板的id是int, 审批的是varchar的数字, 如果改审批表的话, 会影响到很多模块. 就优化了一下SQL. 因为本身是左关联, 就先把主表写了一个查询, 只查询10条数据, 然后再将子查询作为临时表去关联审批表, 这样的话就算全表扫描, 也就扫10条数据, 优化后只需要10ms, 当然最好的方法还是去改字段类型.



批量修改字段:

数据库保存一条条的存储明细, 出库要更新状态, 如果一次出库1w条数据的时候, 写的是一个in的操作, 就是查出这一批出库的id, 然后update 状态 in select 这些id, 走的类型是个range, 大概是8秒. 后来结合数据自身情况, 结合自增主键, 查询出1w里面最大的那个值, 然后更新比这个值小的数据就行. 最后走的是index merge, 把几个索引合并起来, 优化完是3s, 提升了不少.



1. 升级MySQL, 从5升到8. 因为8优化了存储引擎. 官方文档说8支持对索引拆分, 就是一个大索引拆分为小索引, 类似与1.7CHM的分段锁思想, 索引拆分可以减少锁的冲突, 因为在写操作时会对索引更新, 拆分索引后可以缩小锁的粒度, 虽然官方这么说, 但是我也没试过, 但是还要以压测结果为主.
3. 索引失效导致: 全表扫描的SQL

   1. like '%xx', 如果非要这样检索, 可以多加个反转字段, 或者使用<u>全文检索</u>, 或者用ES
   2. in 大数据量; 大概in 20% 到 30%的数据会失效, 如果没失效会走range
   3. where 函数
   4. 关联条件 类型不一致
   5. is null
3. 还要考虑回表的问题.
4. 同时要通过慢查询日志监控. 拿到慢查询日志通过EXPLAIN来分析
6. 数据库设计

   1. 索引字段最好是递增的, 避免删除修改树结构频繁变动;
   2. 字段数字更好, 因为字符串是逐个比较;
6. 表结构设计, 不一定要遵循数据库范式, 而是要尽量避免关联查询.
8. 合理分表

   1. 垂直拆分, 减少单条数据大小, 让聚簇索引容纳更多的数据, 减少树高度.
   2. 水平拆分
      1. 按字段数据的Hash值拆分
      2. 按照时间拆分
9. 设置合理参数值

   1. buffer_pool, 一般推荐物理内存的50%-80%
   2. jion_buffer_size
   3. read_buffer_size



优化硬件层面: 优先优化磁盘, 用速度更快的磁盘; 或者加内存, 内存越大缓冲池就越大.

架构层面: 做集群, 一主一从理论上读的性能会提升一倍; 或者加缓存, 比如二级缓存Redis, 一级缓存caffeine



# 单表2000W是怎么回事?

一页16k, 大约15k可以用来存数据. 

如果1条数据1k, 3层B+树就是2000W.

如果1条数据5k, 4层B+树就是500W.



# 大批量修改操作如何优化?





# 红黑树和AVL树的比较

|        | AVL树                           | 红黑树                                       |
| ------ | ------------------------------- | -------------------------------------------- |
| 平衡度 | 严格平衡, 左右子树高度差不超过1 | 大致平衡, 最长路径不超过最短路径的两倍       |
| 读效率 | 读效率高                        |                                              |
| 写效率 | 调整代价大                      | 写效率较高, 插入删除复杂度logn, 调整代价较小 |



# LSM-Tree

Log Structed Merge Tree. Myrocks存储引擎默认LSM-Tree. 是一种数据组织的方式, 既有磁盘部分又有内存部分.

B+树适合读多写少, LSM树适合写多读少.

LSM树空间利用率更高, 所以占用空间小.



Log-Structured Merge-Tree用来处理大量写入操作, LSM-Tree将数据分为两部分, 一部分放在内存, 一部分放在磁盘, 内存里可以用红黑树或者跳表.

新数据来的时候先存在内存, 定时写到磁盘. 

内存数据通过WAL技术保证不丢失, 先写一段日志. 

当内存到达一定阈值的时候, 会把这部分内存数据按顺序写的方式原封不动写入磁盘.



同一条数据, 又要写入磁盘, 又要对其进行修改怎么办?

当内存中数据达到一定阈值时, 将数据标记为只读, 新的数据再来的时候, 在内存中开辟新的空间, 新数据放入新的空间. 将只读的数据部分进行写磁盘.



磁盘中的一块叫做SSTable(Sorted String Table) , 每一块都是个跳表(有序的).

磁盘中的数据根据操作的热度进行分层, 第一层中的不同块会有同一条数据的不同版本(因为是将整个Immutable Memtable写入磁盘的), 第一层的数据归并排序后放入第二层, 所以不会有重复的了.



每一层都有个布隆过滤器, 如果要查的数据不在, 则去下一层找.
