# Redis

**为什么要用Redis? Redis的使用场景?**

MySQL能承受 写的并发600/s, 读2000/s. 

如果说有更大的并发量, 我们需要用redis做缓存. redis并发量是10万/s. 

redis可以做 排行榜.

redis还能做 计数器: 包括实现限流, 浏览次数, 播放量, 点赞.



**Redis对比Memcached**

|            | Redis                                        | Memcached            |
| ---------- | -------------------------------------------- | -------------------- |
| 数据类型   | 丰富                                         | String型, 二进制类型 |
| 操作       | CRUD, 单个操作, 批量操作, 事务, Lua          | CRUD                 |
|            | 发布订阅, 主从高可用(哨兵, 故障转移), 序列化 | 多线程服务           |
| 网络IO模型 | 网络IO是多线程                               | 多线程非阻塞IO       |
| 持久化     | 支持                                         | 不支持               |



**Redis为什么快?**

Redis为什么快?

1.基于内存; 2.单线程避免线程切换, 使用pipeline 1s可以执行100w请求; 3.渐进式rehash; 4.缓存时间戳, 如果获取时间戳需要系统调用影响性能, 由另外的线程每毫秒更新一次缓存的时间戳.

渐进式ReHash

问题: 两个哈希表, 一开始哈希表数组的长度是16, 现在需要扩容, 因为数组的长度变了, 元素需要ReHash计算自己在新数组的位置并且移动. 如果哈希表数组的长度达到10万个, 要对10万个元素进行移动的话, 会阻塞. 

解决方式: 渐进式ReHash, 把一次大量的拷贝的开销, 分摊到多次处理请求的过程中. 例如数组上有10万个元素, 对所有元素进行ReHash可能要耗费1秒钟, 但是可以将其分摊到10万个请求中. 每次处理请求的时候, 都将 旧数组上的一个位置 的所有entry 移动到新数组上. 



# Redis数据结构

| 底层数据结构        |                                                              |
| ------------------- | ------------------------------------------------------------ |
| 简单动态字符串SDS   | C语言的字符串获取长度麻烦, 不能包含'/0', 不能修改. 所以定义了个结构体, 包括len:已使用的字节数, alloc:buf申请的字节数, flags:标识不同的SDS类型, buf[]:数据. |
| IntSet              | 元素唯一且有序. encoding:编码方式, 16位, 32位, 64位整数; length:元素个数; contents[]:数据 |
| Dict(HashMap)       | DictHashTable {table指向dictEntry的指针; size:数组的大小; sizemask:size的掩码=size-1; used:entry个数}, DictEntry {key, val, next:冲突时的链表}, Dict |
| ZipList             | ZipList:{总字节数, 尾结点偏移量(快速找到尾结点), entry结点个数.}; entry: {前一结点长度, 数据类型和长度, 数据} |
| QuickList(双向链表) | 每个结点是个ZipList, 解决太长的ZipList内存装不下             |
| SkipList            | 链表一次跳1步, 查询效率低. SkipList是有序的, 结点中存多个不同步长的指针. |
| RedisObject         | {type:数据类型(String, Hash...); encoding; lru:记录最近一次被访问的时间; refcount:引用计数器用来回收; ptr:指向数据} |



redis的key怎么命名? "业务名:对象名id[:属性]", 例如 "mall:order:1", 代表数据库mall的表order的第1行

| Redis的数据结构 |                                                              | 应用场景                                                     |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| String          | SDS实现                                                      |                                                              |
| List链表        | QuickList实现, brpop时, 如果没元素会阻塞, 直到有元素或超时. 类似于MQ. | 可以实现文章的列表, 文章列表需要分页, 并且有序, 还需要范围查询. 用来实现消息中间件MQ, MQ有个延时消息(延时队列); 生产者将消息放入MQ, 让消费者10分钟后去消费这条消息, 例如 锁定座位后10分钟内支付订单 |
| Hash            | Dict实现, key对应的value是一组键值对                         | DB表怎么存在Redis? 方法1: 一行就是一个对象, 将这个对象序列化(也可以序列化为JSON)存入String类型的value. 序列化与反序列化有开销; (推荐)方法2: <user:1, [name:zzz, age:18, city:Shanghai]>. |
| Set集合         | Dict实现, 可以进行交集, 并集, 差集等操作                     | 可以用来打标签, 一个用户可能被贴上喜欢体育, 计算机, 音乐这样的标签, 有了这些标签就可以找兴趣相同的人也就是标签有交集的人. |
| ZSet有序集合    | Dict + SkipList, 可以看作是根据value排序的HashMap, 每个Node都有个score作为value, 根据score排序. | 可以用来做排行榜, 可以不实时, zrank 一般用定时任务去算, 可能隔段时间算一次; 延时消息会用到Zset, score是到期时间, 多线程去轮询Zset |
| BitMap位图      |                                                              | 一个数组{1, 3, 5, 7}, 用BitMap怎么记录? 用一个Byte就可以: 10101010. |
| HyperLogLog     |                                                              | 要统计大型网站的每个网页每天的UV(Unique Visitor, 独立访客)数据, 一个用户访问多次只算1, 也就是要去重. 如果用Set, 如果一个页面一天一百万占用空间就是80M, 1年就是28G. 如果用HyperLogLog一天就是15k, 一年5M |
| Stream          | 和Hash数据结构类似, stream的每个entry有个id                  |                                                              |

<u>布隆过滤器</u>: 用来判断一个元素是否 不在 一个集合, 实现方式: BitMap + Hash算法. 

判断x不在集合: 将x哈希, 如果哈希出来的位置是0, 代表x不在集合中; 如果哈希出来的位置是1, 不能代表x在集合中

应用: 黑名单, 垃圾过滤, 缓存穿透.



# Redis实现限流

| 限流算法   |                                                              |
| ---------- | ------------------------------------------------------------ |
| 固定窗口   |                                                              |
| 滑动窗口   | zset实现                                                     |
| 漏桶算法   | 请求放到桶里, 桶里面==平滑==滴出请求. 如果桶满了, 新的请求会丢弃. zset + 定时任务实现 |
| 令牌桶算法 | 固定速率向桶中放令牌(满了不放). 拿到令牌才处理请求. 流量低时桶里会堆积一些, 可以应对突发的流量. |



固定窗口限流lua脚本: Redis存一个过期时间60s的key, value用来作计数器, 当请求来的时候判断计数器是否超过了10, 如果超过则不处理该请求;

```lua
-- KEY[1] 限流的key

-- ARGV[1] 次数
-- ARGV[2] 秒
local key = KEYS[1];  -- 当前<key, 次数>
local times = ARGV[1];
local expire = ARGV[2];

-- expire秒内不能超过times次, 用固定窗口实现,

local val = redis.call('incr', key);
if val == 1 then
    redis.call('expire', key, tonumber(expire))
    return 1
end
if val > tonumber(times) then
    return 0
end
    return 1
```

滑动窗口限流lua脚本: 

```lua
-- 滑动窗口实现 ARGV[1] 秒内不超过 ARGV[3]次请求

--KEYS[1]: 限流 key
--ARGV[1]: 限流窗口,毫秒
--ARGV[2]: 当前时间戳（作为score）
--ARGV[3]: 阈值
--ARGV[4]: score 对应的唯一value
-- 1\. 移除开始时间窗口之前的数据
redis.call('zremrangeByScore', KEYS[1], 0, ARGV[2]-ARGV[1])
-- 2\. 统计当前元素数量
local res = redis.call('zcard', KEYS[1])
-- 3\. 是否超过阈值
if (res == nil) or (res < tonumber(ARGV[3])) then
    redis.call('zadd', KEYS[1], ARGV[2], ARGV[4])
    redis.call('expire', KEYS[1], ARGV[1])
    return 0
else
    return 1
end
```



# Redis其他

| Redis       |                                                              |
| ----------- | ------------------------------------------------------------ |
| Redis慢查询 | 记录每条命令执行的时间, 如果一条命令执行的比较慢, 超过了设置的阈值, 则就会将这条命令的相关信息(执行的时刻, 耗时, 命令的详细信息)记录下来, 作为慢查询日志. 帮助我们找到Redis目前的瓶颈 |
| Pipeline    | 如果一次请求执行一条命令, 大部分时间都浪费在RTT(Round-Trip Time)上. 所以我们可以一次请求执行多条命令, 就是Pipeline. 使用Pipeline的时, 内核输入输出的缓冲区4k~8k, 不超过单个TCP报文的最大值1460字节(MTU是1500字节, IP头20个字节, TCP头20个字节) |
| Lua         | 因为Redis是单线程, 我们可以把多个命令放在同一个lua脚本中, Redis会将整个lua脚本作为一个整体执行, 中间不会被其他命令插入. lua脚本可以存储在redis, 可以让其他客户端复用. |
| Redis事务   | 不支持回滚, multi和exec之间的命令放在一个队列中, exec后开始执行. 如果出现语法错误则会不执行; 如果出现运行时错误, 则不回回滚. |
| watch       | watch监听某个key, 对这个key的操作都是CAS操作                 |
| Redis实现MQ |                                                              |

redis eval命令执行Lua

```shell
# script表示要执行的lua脚本, numkeys表示脚本中使用键的数量
# 在Lua中通过KEYS访问key1, 在Lua中通过ARGV访问arg1
EVAL "return {KEYS[1], KEYS[2], ARGV[1], ARGV[2]}" numkeys key1 [key2...] arg1 [arg2...]
```

Lua中调用Redis命令

```shell
# call()错误时, 会引发Lua错误
# pcall()错误时, 会捕获错误并返回一个错误信息表
EVAL "redis.call('mset', KEYS[1], ARGV[1], KEYS[2], ARGV[2])" 2 key1 key2 v1 v2
```

保存lua命令

```shell
script load "redis.call('mset', KEYS[1], ARGV[1], KEYS[2], ARGV[2])"
```

执行存起来的lua命令

```shell
evalsha "上跳命令返回的串" 1 key3 v3
```



# Redis线程模型

对于Redis, CPU不是瓶颈, 受制于 内存和网络. 想提高Redis的性能, 可以用Pipeline(命令的批量处理), 用了Pipeline可以达到处理100W/s请求

单线程内部维护成本低, 没有线程安全问题.



单线程指的是只用一个线程执行命令, 接收客户端请求->解析请求 ->数据读写操作->返回数据给客户端 这个过程是由一个线程完成的.

2.6版本: 启动2个后台线程分别处理<u>关闭文件</u>, <u>AOF刷盘</u>任务.

4.0版本: 新增1个后台线程lazyfree<u>释放Redis内存</u>, 也就是专门用来执行 unlink key / flushdb async / flushall async命令.

6.0版本: <u>默认3个线程专门处理IO</u>, 默认只多线程写Socket. 可以开启多线程读.



# Redis IO模型

epoll_create()创建epoll实例, 实例中包括 红黑树, 链表.

epoll_ctl()注册fd; epoll_del()删除fd;

epoll_wait()等待fd就绪, 可设置最大等待时间.



# Redis通信协议

RESP协议, 根据首字符区分不同数据类型, 常用的有5种: 1.单行字符串; 2.错误; 3.数字值; 4.多行字符串; 5.数组;



# Redis内存淘汰机制

过期Key的处理:

1. 定时删除: 设置key的存活时间时, 创建一个定时事件.
2. 惰性删除: 每次访问到这个过期key的时候, 才会删除. 对内存不友好
3. 定期删除: 每段时间随机抽一部分key来检查是否过期并删除.



内存淘汰机制:

1. 不淘汰, 内存满时不允许插入数据.
2. 淘汰TTL小的
3. 随机淘汰, 可以对全体Key, 也可以对设置了TTL的Key;
4. LRU, 可以对全体Key, 也可以对设置了TTL的Key;
5. LFU, 可以对全体Key, 也可以对设置了TTL的Key;



# Redis持久化机制

## RDB(Redis DataBase)

全量快照

根据配置的时间或者手动执行BGSAV或SAVE命令, Redis就会生成RDB文件, RDB文件是经过压缩的二进制文件, 可以通过这个文件在启动的时候还原数据.

Redis是单线程的, 执行BGSAV或SAVE命令的时候, 其他请求需要等待吗? 

SAVE命令会阻塞; 

BGSAVE命令会fork出一个子进程, 主进程fork操作的时候是阻塞的, fork完后, 子进程去完成持久化, 主进程该干啥干啥. 

当子进程正在对其中一块数据进行复制, 父进程也要对这块数据进行修改时, 咋办? 为了不让子进程阻塞, 要 **写时复制**, 父进程对这块数据复制, 子进程将复制出来的副本写入磁盘.

RDB会丢失一些数据, 在BGSAVE几秒后Redis宕机了, 因为是写时复制, 这几秒的数据就丢了.



## AOF(Append Only File)

把Redis服务器接收到的所有写命令都记录到日志中. Redis重跑一遍这个记录下的日志文件, 就可以还原数据. 

AOF在命令执行完后, 每条命令都写入磁盘会比较慢, 所以把命令append写在内存中的AOF缓冲区, 每秒(或者每条命令, 或者永不)将缓存区中的命令写入磁盘.

丢失只会丢失1秒的数据

问题: 命令会一直变多, 所以会fork个子进程进行压缩



# Redis集群与分片

| Redis实现高可用 |                                                              |
| --------------- | ------------------------------------------------------------ |
| 主从复制        | 一个主结点, 多个从结点. 主结点是读写, 从结点是只读. 缺点是主结点挂了就没有写操作了. |
| 哨兵机制        | Sentinel监控各个结点的情况, 当主结点出现了故障, 能自动将一个从结点转换为主结点. |



如果一台Redis无法缓存, 需要分片集群.

| Redis数据分片思想 |                                                    |
| ----------------- | -------------------------------------------------- |
| 虚拟槽分区        | 通过哈希将数据映射到16483个槽, 如果太多, 浪费带宽. |



# 数据一致性(数据同步)

如果不加锁, 则不可能是强一致性, 所以下面讨论如何做到最终一致性.

到底删除缓存还是修改缓存? 写数据时, 更新缓存成本高, 所以直接将缓存相应的数据删除. 

到底先操作数据库还是后操作数据库? 推荐先操作数据库, 再删除缓存, 即可最终一致. 如果先删缓存, 则会导致其他线程将老数据写到缓存, 而数据库中是新数据.



| 读写并发会出现数据不一致的问题                               |                              |
| ------------------------------------------------------------ | ---------------------------- |
| ==延迟双删==, redis.delKey(x); db.update(x); Thread.sleep(500ms); redis.delKey(x). 异步延迟双删, 用RocketMQ的定时任务实现延迟. | 操作数据库前后都删一下Redis. |
| 阿里巴巴canal进程专门负责删除缓存, 监听binlog, binlog修改后canal去延迟删除缓存, 如果删除失败, 发送消息到MQ, MQ的订阅者执行删除重试. | 删除缓存失败怎么办?          |

进程A更新数据库为3, 进程B更新数据库为4, 进程B更新缓存为4, 进程A更新缓存为3, 最后的结果缓存中是3, 数据库是4, 缓存和数据库数据不一致了.



# Redis缓存失效问题

## 缓存击穿

MySQL的性能: 500万数据, 主键索引7万QPS, 普通索引2700QPS, 600QPS指的是没索引的.

缓存击穿会引发什么问题? 

只基于Redis来考虑的话就是 设置Key永不过期, 加锁访问数据库.

从架构层面来考虑: 

1. 需要了解所有缓存的数据, 如果缓存失效, 数据库的耗时. 就是每个数据用缓存是多少耗时, 不用是多少. 一般查询要求200ms/s内. 
2. 监控热点缓存, 即将过期的时候告警或者主动延时;
3. 系统降级熔断策略, 如果MySQL真挂了, 大量请求超时. 需要熔断对数据库的查询操作, 防止全链路依赖MySQL的请求都挂了.

热点key不能完全准备, 所以重点关注在保底方案.

| 问题                                                         | 解决方式                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 缓存穿透: 攻击者查询Redis和MySQL都不存在的key                | 1.参数校验; 2.缓存空对象, 查询MySQL返回null也存Redis; 3.==布隆过滤器==先判断请求的key是否在缓存中, 如果不存在就不去查, 如果存在才去查. |
| 缓存击穿: 大量的请求访问同一个key, 突然这个key过期了         | 1.设置热点key永不过期; 2.DCL, 只有一个线程可以查询数据库; 3. 在请求数据库前, 通过redis.setnx()实现互斥; 4. 不删缓存而是修改缓存; |
| 缓存雪崩: Redis挂了, 或者多个key过期                         | 1.解决多个key集中失效可以随机设置失效时间; 2.解决Redis宕机只能做集群. 3.服务降级, 暂停不重要的资源. 4.引入hystrix限流组件; 5.EHCache多级缓存 |
| 热点Key问题                                                  | 二级缓存(Guava-cache, hcache); key分散为多个子key, hash算法随机选择一个子key |
| BigKey问题: value值过大, String类型>10kb, 非String 元素的数量过多. 导致Cluster节点内存空间使用不均匀, bigKey耗时, 阻塞Redis | 去除冗余字段; 采用压缩比更高的压缩方式; 拆分(注意拆分后IO次数增加, 不一定性能变好); 定期扫描大key, 每周消除. |
| 脑裂问题                                                     | 设置原先的主结点数据同步的延迟不超过10s, 如果超过就会拒绝写请求, 从而将主结点的位置让给了新结点. |

缓存失效问题解决方式:

- 设置好key生存时间: 永不过期, 或者随机失效. 业务线程不负责更新缓存, 业务线程发现缓存失效, 发送消息到MQ中, 后台线程监听MQ收到消息更新缓存.
- 互斥锁方案: 限制保证同一时间只有一个线程访问数据库更新缓存.



# 高性能Redis设计方案

1. 主结点不做持久化, 从结点持久化. 因为持久化即使是多线程, 也会占用CPU和内存.
2. 如果数据比较重要, 会开启AOF持久化, 从结点最好是每秒. 
3. 主从结点最好在一个局域网中.
4. 尽量避免主库压力大的时候增加从库
5. 主从复制不要采用网状结构, 尽量用线性结构, 从而减轻主结点的压力. 因为如果主从同步需要给多个从结点发数据, 比较占用带宽.



# 秒杀系统设计(来自携程)

问题一: Redis顶不住

1. 热点Key问题: 如果其中一个Redis结点有2个热点Key, 请求量会高于其他结点. 导致实例负载不均衡, 影响性能.  

   热点Key解决方案: 将热点Key识别出来加入到本地缓存(就实现了多级缓存). 秒杀时, 短暂的本地缓存可以减少Redis单实例热点, 对数据的一致性不会有较大影响.

2. 大Key问题: 大key占用内存, 并且会导致阻塞请求, 阻塞网络等. 

   大Key解决方案: 去除冗余字段; 采用压缩比更高的压缩方式; 拆分(注意拆分后IO次数增加, 不一定性能变好); 定期扫描大key, 每周消除.



问题二: MySQL顶不住, 监听器收到消息后删除相应的缓存Key在高并发场景下存在几个问题:

1. 缓存击穿: 不删缓存而是修改缓存.
2. 消息聚合: 针对商品变化消息量过大的问题, 将商品多次变化消息在一段时间窗口内合并成一个
3. 异步更新缓存: 数据库数据变化, 不会立即更新缓存, 而是将更新任务放入一个异步队列中, 由后台线程异步处理.



问题三: 供应商系统顶不住, 可能会被供应商限流, 或者出现延迟响应或失败.

1. 解决方案一: MQ进行削峰填谷
2. 解决方案二: 建立对供应商系统的健康监控机制, 实时检测其响应速度, 错误率等指标. 一旦发现供应商系统出现不稳定或者限流的情况, 及时出发禁售策略.
3. 解决方案三: 针对失败请求定期重试.



问题四: 流量控制策略的优化, 确保秒杀活动稳定进行

1. SOA限流: 接口与应用级限流. 通过服务治理框架对服务接口进行限流
2. 自定义限流: 商品级限流(滑动窗口)
   1. 针对单个秒杀商品设置独立的限流阈值
   2. 热点商品自动限流



问题五: 数据一致性挑战与应对策略, 库存扣减的精确执行, 这种数据一致性的实现效果会影响订单是否能成功履约.MySQL热点行扣减库存(行级锁)的性能瓶颈

解决方案: 扣减库存异步化, 异步扣减库存分三步 a) 将库存同步至Redis; b) 从Redis扣库存, 通过消息通知异步扣减DB库存; c) 如果有退订, 先判断DB是否有扣减记录, 如果有, 先退订DB, 再退订Redis, 如果没有, 重复多次.

评价: 按照业务“可少卖不超卖”的原则, 即使在这个过程中数据可能存在短暂的延时, 但能保证最终一致性



# 项目中使用redis

消息推送平台发送消息后, 需要知道消息有没有下发成功, 就需要有一套完整的链路追踪体系, 其中实时的数据就用Redis来存储(离线数据存在Hive), 对消息进行实时链路追踪, 会用到Set, List, Hash.

要发消息之前需要在后台新建一个模板, 对模板的ID进行扩展, 比如加上日期和固定的业务参数, 形成的ID可以唯一标识某个模板的下发链路. 系统上, 我这边叫它为UMPID, 在发送入口处会对所有需要下发的消息打上UMPID, 然后在关键链路上打上对应的点位.

接下来的工作就是清洗出统一的模型, 然后根据不同维度进行处理, 例如: 

我要看某一天下发的所有模板有哪些, 那只要我把清洗出来后的数据对应的UMPID扔到Set; 

我要看某一个模板的消息下发的整体链路情况, 就以UMPID为key, Value是Hash<state, 人数>, state是在下发的过程中打的关键点位, 比如接收到消息打个51, 消息被去重了打个61, 消息成功下发了打个81. 以UMPID为Key, Hash结构的Key（State）进行不断的累加, 就可以实现某一个模板的消息下发的整体链路情况.

我要看某个用户当天下发的消息有哪些, 以及这些消息的整体链路是如何, 用的是List结构, Key是userId, Value则是UMPID+state(关键点位)+processTime(处理时间)

通过Redis丰富的数据结构来实现对下发消息多个维度的统计, 不同的应用场景选择不同的数据结构, 再等到透出做处理的时候, 就变得十分简单了. 

因为Redis拥有丰富的数据结构, 在透出的时候, 处理会非常的方便. Redis的话, 还得做很多解析的工作. 综合上面并发量和实时性以及数据结构, 用Redis是一个比较好的选择

























